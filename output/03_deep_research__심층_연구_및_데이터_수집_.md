# Chapter 3: deep_research (심층 연구 및 데이터 수집)

---

## 들어가며: 왜 심층 연구 엔진이 필요한가?

이전 단계에서는 사용자가 입력한 리서치 주제에 대해 후속 질문을 자동으로 만들어 "무엇을 더 알아보아야 할지"를 밝혀냈습니다.

이제 본격적으로 인터넷에서 자료를 찾아 정보를 모으는 단계가 필요합니다.  
이 과정은 단순히 검색 한 번으로 끝나는 것이 아니라,  
1) 어떤 키워드로 검색할지 정하고  
2) 관련 자료를 수집하며  
3) 요약 및 새로운 단서(검색 키워드)를 얻고  
4) 다음 단계로 더 깊게 파고드는  
반복적인 **탐정 놀이**와 같습니다.

이 역할을 담당하는 것이 바로 `deep_research` 함수입니다.

---

## 핵심 아이디어

1. **검색 키워드 생성:**  
   탐구할 주제에서 파생되는 검색 키워드를 자동으로 만들어냅니다.

2. **실제 자료 수집:**  
   (다음 챕터에서 자세히 배우겠지만) Firecrawl 검색 API를 사용해 실제로 웹에서 관련 문서/정보를 가져옵니다.

3. **학습 내용 및 후속 질문 추출:**  
   가져온 자료를 읽고, '무엇을 알게 되었는지'와 '추가로 궁금한 점(후속 질문)'을 정리합니다.

4. **재귀적(계속 반복적으로) 심화:**  
   위에서 얻은 후속 질문들을 바탕으로 다시 검색 키워드를 만들어 더 깊이 조사합니다.  
   이 과정을 depth(깊이)만큼 반복합니다.

즉, 사람이 검색을 통해 '정보-의문-정보'를 반복하면서 점점 더 연구를 완성하는 방식을 그대로 자동화한 것입니다.

---

## 단계별 코드와 흐름 설명

코드는 여러 함수로 구성되어 있습니다.  
각 함수가 어떤 역할을 하는지, 쉬운 예시와 함께 하나씩 살펴봅시다.

---

### 1. 검색 키워드(SERP 쿼리) 자동 생성

```python
def generate_serp_queries(
    query: str,
    client,
    model: str,
    num_queries: int = 3,
    learnings: Optional[List[str]] = None,
) -> List[SerpQuery]:
    #  ... 생략 ...
```

#### 쉽게 설명하면?

- 사용자가 궁금한 주제를 입력하면, "이 주제를 조사하기 위해 어떤 키워드로 검색할까?"를 AI에게 물어봅니다.
- 예를 들어, *"딥러닝의 최근 트렌드"*가 입력이라면  
  → ["딥러닝 최신 논문 동향", "딥러닝 산업 적용 사례", "딥러닝 연구 한계"]  
  이런 식의 실제 검색어(SERP 쿼리)를 생성합니다.

- 즉, **자동으로 검색어 브레인스토밍**을 대신해줍니다.

---

### 2. 웹에서 실제 자료 긁어오기

(다음 챕터에서 자세히, 여기선 함수 껍데기만 소개합니다.)

```python
def firecrawl_search(query: str, timeout: int = 15000, limit: int = 5) ->List[SearchResult]:
    # Firecrawl API로 검색하고 자료를 가져온다
```

#### 쉽게 설명하면?

- 위에서 뽑은 키워드로 웹을 실제로 검색해서 글/요약/URL 등을 가져옵니다.
- **사람 대신 인터넷 서핑**을 해주는 역할입니다.

---

### 3. 자료 요약 및 후속 질문 만들기

```python
def process_serp_result(
    query: str,
    search_result: List[SearchResult],
    client,
    model: str,
    num_learnings: int = 5,
    num_follow_up_questions: int = 3,
) -> Dict[str, List[str]]:
    # 가져온 자료에서 알게 된 점, 추가로 궁금해진 점을 추린다
```

#### 쉽게 설명하면?

- 인터넷에서 긁어온 자료를 읽고,  
  *"아, 이런 점을 알게 됐네!"* (학습 내용)  
  "그런데 이 부분은 더 궁금하구나" (후속 질문)  
  식으로 요점을 뽑아줍니다.

- 예시)  
  - 학습 내용: "딥러닝은 이미지 분석에 가장 많이 쓰인다."  
  - 후속 질문: "딥러닝이 자연어 처리에 어떤 효과를 주는가?"

---

### 4. 자동화된 심층 탐색 (재귀적 반복)

이제 핵심 엔진인 `deep_research` 함수입니다.

```python
def deep_research(
    query: str,
    breadth: int,
    depth: int,
    client,
    model: str,
    learnings: Optional[List[str]] = None,
    visited_urls: Optional[List[str]] = None,
) -> ResearchResult:
    # 전체 심층 리서치 엔진
```

#### 주요 흐름

1. 우선, 주제를 파고들 키워드(검색어)들(`breadth` 수만큼)을 생성합니다.
2. 각 키워드마다:
   - 관련 자료를 검색하고
   - 자료를 읽어 알게 된 점과 다음에 궁금할 점(후속 질문)을 정리합니다.
   - 정보를 모으고, 어떤 웹사이트를 방문했는지 기록합니다.
3. **깊이(`depth`)가 남아 있다면**:  
   - 이번에 새로 나온 후속 질문들을 '다음 탐색 주제'로 삼아  
   - 1~2번을 다시 반복합니다.  
   - 이 과정을 depth만큼(예: 최대 3뎁스) 반복합니다.
4. 모든 과정을 마치면,  
   - 전체에서 알아낸 주요 정보(요약)와  
   - 방문한 웹사이트 목록(중복 없이)을 반환합니다.

#### 예시 비유

- 마치 '사건의 실마리 → 조사 → 추가 단서 → 다시 조사' 과정처럼, 지식의 미로를 자동 탐색합니다.
- 사람 리서처가 "`이 키워드를 검색해볼까? → 이걸 알고 나니 이런 것도 궁금하네?`" 자연스럽게 확장하는 사고 과정을 코드로 구현했다고 보면 됩니다.

---

## 마무리: 전체 흐름 정리

- 사용자의 질문에서 시작해  
- 자동으로 검색 키워드를 만들고  
- 인터넷을 대신 서핑하여  
- 핵심만 요약, 깊은 질문까지 만들어  
- 더 궁금한 것을 바탕으로 재귀적으로 (여러 단계) 자료를 탐색  
- 마지막에는 "내가 알아낸 것"과 "방문한 사이트" 리스트를 반환합니다.

이제 이 자동화된 심층 리서치 엔진을 구축함으로써,  
**실제 사람처럼 '정보 → 요약 → 다음 질문 → 더 깊이' 형식의 리서치를 손쉽게 파이썬으로 해볼 수 있습니다.**

다음 챕터에서는 Firecrawl API를 실전에서 어떻게 연동해서 웹 자료를 가져오는지를 자세히 알아보겠습니다! 🚀